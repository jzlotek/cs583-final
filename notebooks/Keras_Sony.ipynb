{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZVOokgnh5HV"
   },
   "source": [
    "# Read the README [in the repository](https://github.com/jzlotek/cs583-final) before continuing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49FnX_pjGfZR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Sony data... (25GB)\n",
      "100.00% downloaded\n",
      "Unzipping, this will take a while...\n",
      "Usage of storage should be around 117GB\n",
      "Data ready in ./dataset/Sony\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# download_dataset.py\n",
    "#\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "import sys\n",
    "from zipfile import ZipFile\n",
    "\n",
    "OUTDIR='./dataset'\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = f\"https://storage.googleapis.com/isl-datasets/SID/{id}\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, stream = True, timeout=None)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True, timeout=None)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 10000\n",
    "    downloaded = 0\n",
    "    total = 26926678016.00 * 1.1 / 100.00\n",
    "    sys.stdout.write(\"\\r0.00% downloaded\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "                downloaded+=len(chunk)\n",
    "                if downloaded % (CHUNK_SIZE*50) == 0:\n",
    "                    sys.stdout.write('\\r%0.2f%% downloaded' % (downloaded/(total)))\n",
    "    sys.stdout.write(\"\\r100.00% downloaded\")\n",
    "\n",
    "# Ensure directory exists\n",
    "if not os.path.exists(OUTDIR):\n",
    "  os.mkdir(OUTDIR)\n",
    "\n",
    "filepath = OUTDIR+'/Sony.zip'\n",
    "# Too much data, download the smaller dataset for now\n",
    "print('Downloading Sony data... (25GB)')\n",
    "download_file_from_google_drive('Sony.zip', filepath)\n",
    "\n",
    "fileout = OUTDIR+'/Sony'\n",
    "# Always unzip to reset directory\n",
    "print('\\nUnzipping, this will take a while...')\n",
    "print('Usage of storage should be around 117GB')\n",
    "ZipFile(filepath).extractall(path=OUTDIR)\n",
    "\n",
    "    \n",
    "print(\"Data ready in %s\" % (fileout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGTHg8HGiYmB"
   },
   "source": [
    "Data is downloaded, time to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMPKXMwObXGW"
   },
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install rawpy\n",
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KtTAfR4VtlaP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #0\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.2254 - acc: 0.1785\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.2208 - acc: 0.1732\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.2158 - acc: 0.1659\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.2106 - acc: 0.1572\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.2050 - acc: 0.1482\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.1985 - acc: 0.1403\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.1926 - acc: 0.1358\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.1917 - acc: 0.1355\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.1907 - acc: 0.1353\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.1897 - acc: 0.1351\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.1886 - acc: 0.1350\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #1\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.3359 - acc: 0.0371\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.3131 - acc: 0.0355\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.2784 - acc: 0.0345\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.2643 - acc: 0.0338\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.2414 - acc: 0.0351\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.2174 - acc: 0.1068\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.2048 - acc: 0.3386\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.2029 - acc: 0.3847\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.2007 - acc: 0.4372\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.1986 - acc: 0.4975\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.1967 - acc: 0.5652\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #2\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.1568 - acc: 0.5967\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.1591 - acc: 0.6784\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.1547 - acc: 0.6809\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.1480 - acc: 0.6810\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.1460 - acc: 0.6808\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.1445 - acc: 0.6804\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.1426 - acc: 0.6804\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.1422 - acc: 0.6804\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.1417 - acc: 0.6805\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.1412 - acc: 0.6805\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.1407 - acc: 0.6806\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #3\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 269ms/step - loss: 0.1191 - acc: 0.7234\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.1038 - acc: 0.7238\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0813 - acc: 0.7242\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0725 - acc: 0.7243\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0766 - acc: 0.7230\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0608 - acc: 0.7087\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0574 - acc: 0.5866\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0576 - acc: 0.5743\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0575 - acc: 0.5729\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0571 - acc: 0.5808\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0565 - acc: 0.5965\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #4\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0621 - acc: 0.5841\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0573 - acc: 0.6143\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0519 - acc: 0.6022\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0543 - acc: 0.5601\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0543 - acc: 0.5167\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0515 - acc: 0.4889\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0503 - acc: 0.4777\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0503 - acc: 0.4784\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0504 - acc: 0.4810\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0503 - acc: 0.4853\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0503 - acc: 0.4908\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #5\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 269ms/step - loss: 0.1252 - acc: 0.6902\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.1154 - acc: 0.7405\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.1067 - acc: 0.7333\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.1020 - acc: 0.7525\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.1000 - acc: 0.8214\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0992 - acc: 0.8978\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0986 - acc: 0.9376\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0985 - acc: 0.9412\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0983 - acc: 0.9452\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0981 - acc: 0.9489\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0978 - acc: 0.9523\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #6\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0653 - acc: 0.6361\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0642 - acc: 0.6389\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0628 - acc: 0.6394\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0612 - acc: 0.6397\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0593 - acc: 0.6397\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0575 - acc: 0.6397\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0565 - acc: 0.6397\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0563 - acc: 0.6396\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0561 - acc: 0.6396\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0559 - acc: 0.6396\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0556 - acc: 0.6395\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #7\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0855 - acc: 0.8720\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0797 - acc: 0.8702\n",
      "Epoch 3/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0728 - acc: 0.8543\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0721 - acc: 0.6501\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0731 - acc: 0.2603\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0704 - acc: 0.1520\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0674 - acc: 0.1604\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0670 - acc: 0.1725\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0666 - acc: 0.1955\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0662 - acc: 0.2314\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0657 - acc: 0.2826\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #8\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0573 - acc: 0.3946\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0548 - acc: 0.4587\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0562 - acc: 0.4663\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0581 - acc: 0.4667\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0571 - acc: 0.4664\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0548 - acc: 0.4628\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0539 - acc: 0.4491\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0539 - acc: 0.4462\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0538 - acc: 0.4433\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0538 - acc: 0.4406\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0538 - acc: 0.4382\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #9\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0800 - acc: 0.5588\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0776 - acc: 0.4629\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0779 - acc: 0.5020\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0770 - acc: 0.6090\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0764 - acc: 0.6539\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0770 - acc: 0.6642\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0766 - acc: 0.6643\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0764 - acc: 0.6635\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0762 - acc: 0.6620\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0760 - acc: 0.6598\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0758 - acc: 0.6569\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #10\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.1570 - acc: 0.3768\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.1236 - acc: 0.4023\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.1322 - acc: 0.4564\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.1361 - acc: 0.4757\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.1224 - acc: 0.4718\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.1112 - acc: 0.4635\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.1165 - acc: 0.4535\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.1161 - acc: 0.4510\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.1144 - acc: 0.4484\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.1122 - acc: 0.4452\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.1098 - acc: 0.4413\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #11\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.1065 - acc: 0.0513\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.1142 - acc: 0.5127\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.1137 - acc: 0.8906\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.1064 - acc: 0.9536\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0920 - acc: 0.9591\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0691 - acc: 0.9602\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0455 - acc: 0.9607\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0425 - acc: 0.9606\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0400 - acc: 0.9606\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0379 - acc: 0.9604\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0363 - acc: 0.9601\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #12\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.1570 - acc: 0.3029\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.1321 - acc: 0.4640\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0904 - acc: 0.7116\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0799 - acc: 0.6852\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0888 - acc: 0.6825\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0954 - acc: 0.6823\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0938 - acc: 0.6823\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0928 - acc: 0.6823\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0912 - acc: 0.6823\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0893 - acc: 0.6823\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0874 - acc: 0.6823\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #13\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.1062 - acc: 0.0530\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.1014 - acc: 0.0564\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0999 - acc: 0.0684\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0996 - acc: 0.1187\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0977 - acc: 0.2899\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0941 - acc: 0.6464\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0911 - acc: 0.7821\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0907 - acc: 0.7862\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0903 - acc: 0.7889\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0899 - acc: 0.7907\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0894 - acc: 0.7919\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #14\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0605 - acc: 0.8679\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0580 - acc: 0.8705\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0572 - acc: 0.8708\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0554 - acc: 0.8702\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0545 - acc: 0.8689\n",
      "Epoch 6/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0554 - acc: 0.8675\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0560 - acc: 0.8666\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0559 - acc: 0.8666\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0557 - acc: 0.8667\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0555 - acc: 0.8668\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0552 - acc: 0.8670\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #15\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.1123 - acc: 0.8561\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0979 - acc: 0.8698\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0719 - acc: 0.8738\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0561 - acc: 0.8745\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0582 - acc: 0.8744\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0605 - acc: 0.8740\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0566 - acc: 0.8736\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0553 - acc: 0.8736\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0537 - acc: 0.8735\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0519 - acc: 0.8735\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0502 - acc: 0.8734\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #16\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0873 - acc: 0.4670\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0781 - acc: 0.4664\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0776 - acc: 0.4649\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0799 - acc: 0.4621\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0824 - acc: 0.4564\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0833 - acc: 0.4466\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0828 - acc: 0.4349\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0825 - acc: 0.4331\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0821 - acc: 0.4312\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0816 - acc: 0.4292\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0810 - acc: 0.4272\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #17\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0709 - acc: 0.6102\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0685 - acc: 0.5628\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0671 - acc: 0.5357\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0668 - acc: 0.5443\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0670 - acc: 0.5866\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0672 - acc: 0.6409\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0671 - acc: 0.6704\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0670 - acc: 0.6729\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0668 - acc: 0.6750\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0666 - acc: 0.6769\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0664 - acc: 0.6785\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #18\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.1052 - acc: 0.5818\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0926 - acc: 0.5830\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0865 - acc: 0.5767\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0873 - acc: 0.5563\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0900 - acc: 0.5102\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0905 - acc: 0.4277\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0890 - acc: 0.3512\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0885 - acc: 0.3440\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0879 - acc: 0.3383\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0872 - acc: 0.3340\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0865 - acc: 0.3309\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #19\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0735 - acc: 0.0752\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0601 - acc: 0.0702\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0563 - acc: 0.1594\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0604 - acc: 0.6704\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0605 - acc: 0.8746\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0537 - acc: 0.9072\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0494 - acc: 0.9128\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0490 - acc: 0.9119\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0485 - acc: 0.9098\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0480 - acc: 0.9066\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0475 - acc: 0.9024\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #20\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.1264 - acc: 0.7404\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.1161 - acc: 0.7287\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.1081 - acc: 0.5606\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.1059 - acc: 0.3273\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.1071 - acc: 0.2403\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.1078 - acc: 0.2106\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.1051 - acc: 0.2006\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.1042 - acc: 0.2000\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.1030 - acc: 0.1997\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.1016 - acc: 0.1996\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.1002 - acc: 0.1999\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #21\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0791 - acc: 0.0812\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0682 - acc: 0.0940\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0622 - acc: 0.1272\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0622 - acc: 0.2656\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0643 - acc: 0.6523\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0649 - acc: 0.8345\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0635 - acc: 0.8427\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0631 - acc: 0.8429\n",
      "Epoch 9/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0625 - acc: 0.8432\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0618 - acc: 0.8433\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0610 - acc: 0.8435\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #22\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0819 - acc: 0.7308\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0678 - acc: 0.7310\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0578 - acc: 0.7310\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0530 - acc: 0.7310\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0523 - acc: 0.7310\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0533 - acc: 0.7309\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0541 - acc: 0.7307\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0542 - acc: 0.7307\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0541 - acc: 0.7306\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0541 - acc: 0.7305\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0539 - acc: 0.7305\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #23\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0387 - acc: 0.6742\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0370 - acc: 0.6714\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0359 - acc: 0.6667\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0354 - acc: 0.6578\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0352 - acc: 0.6425\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0352 - acc: 0.6186\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 269ms/step - loss: 0.0352 - acc: 0.5935\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0352 - acc: 0.5901\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0352 - acc: 0.5870\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0351 - acc: 0.5841\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0351 - acc: 0.5814\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #24\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0494 - acc: 0.4454\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0486 - acc: 0.4474\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0478 - acc: 0.4480\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0472 - acc: 0.4466\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0467 - acc: 0.4435\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0464 - acc: 0.4416\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0462 - acc: 0.4403\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0461 - acc: 0.4403\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0461 - acc: 0.4402\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0460 - acc: 0.4404\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0460 - acc: 0.4405\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #25\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0541 - acc: 0.5137\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0526 - acc: 0.5767\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0510 - acc: 0.6840\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0496 - acc: 0.7963\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0484 - acc: 0.8765\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0472 - acc: 0.9186\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0463 - acc: 0.9343\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0461 - acc: 0.9355\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0460 - acc: 0.9367\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0458 - acc: 0.9378\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0456 - acc: 0.9386\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #26\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0351 - acc: 0.9684\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0328 - acc: 0.9718\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0314 - acc: 0.9734\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0308 - acc: 0.9741\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0308 - acc: 0.9743\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0307 - acc: 0.9744\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0306 - acc: 0.9744\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0306 - acc: 0.9744\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0305 - acc: 0.9744\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0305 - acc: 0.9744\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0304 - acc: 0.9744\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #27\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0613 - acc: 0.6479\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0608 - acc: 0.6477\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0597 - acc: 0.6470\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0584 - acc: 0.6451\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0571 - acc: 0.6407\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0560 - acc: 0.6326\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0552 - acc: 0.6228\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0551 - acc: 0.6214\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0550 - acc: 0.6201\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0548 - acc: 0.6191\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0547 - acc: 0.6182\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #28\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0690 - acc: 0.5675\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0678 - acc: 0.5477\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0668 - acc: 0.5301\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0661 - acc: 0.5189\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0654 - acc: 0.5164\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0646 - acc: 0.5215\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0642 - acc: 0.5288\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0642 - acc: 0.5307\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0641 - acc: 0.5335\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0640 - acc: 0.5370\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0639 - acc: 0.5408\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #29\n",
      "Epoch 1/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 293ms/step - loss: 0.1378 - acc: 0.6806\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.1236 - acc: 0.6937\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.1174 - acc: 0.6939\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.1170 - acc: 0.6940\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.1180 - acc: 0.6940\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.1159 - acc: 0.6941\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.1121 - acc: 0.6952\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.1114 - acc: 0.6956\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.1105 - acc: 0.6959\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.1096 - acc: 0.6962\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.1086 - acc: 0.6962\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #30\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0804 - acc: 0.6010\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0743 - acc: 0.4953\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0810 - acc: 0.4356\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0839 - acc: 0.5152\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0792 - acc: 0.6098\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0712 - acc: 0.6332\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0679 - acc: 0.6366\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0678 - acc: 0.6366\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0678 - acc: 0.6366\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0678 - acc: 0.6365\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0677 - acc: 0.6364\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #31\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0497 - acc: 0.7116\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0382 - acc: 0.7038\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0299 - acc: 0.7088\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0317 - acc: 0.6648\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0297 - acc: 0.5568\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0285 - acc: 0.4541\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0299 - acc: 0.4214\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0299 - acc: 0.4268\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0295 - acc: 0.4391\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0290 - acc: 0.4567\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0284 - acc: 0.4779\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #32\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0617 - acc: 0.5378\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0588 - acc: 0.5538\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0580 - acc: 0.5577\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0574 - acc: 0.5583\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0552 - acc: 0.5584\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0517 - acc: 0.5583\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0491 - acc: 0.5572\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0488 - acc: 0.5569\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0485 - acc: 0.5565\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0483 - acc: 0.5563\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0480 - acc: 0.5559\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #33\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0962 - acc: 0.8955\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0871 - acc: 0.8920\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0816 - acc: 0.9001\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0797 - acc: 0.9044\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0780 - acc: 0.9050\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0744 - acc: 0.9054\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0708 - acc: 0.9055\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0702 - acc: 0.9055\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0695 - acc: 0.9055\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0688 - acc: 0.9055\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0682 - acc: 0.9055\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #34\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.1141 - acc: 0.8560\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0791 - acc: 0.7486\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0852 - acc: 0.6147\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0790 - acc: 0.7199\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0682 - acc: 0.8480\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0661 - acc: 0.8727\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0671 - acc: 0.8750\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0670 - acc: 0.8751\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0669 - acc: 0.8751\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0666 - acc: 0.8751\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0662 - acc: 0.8751\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #35\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0948 - acc: 0.8517\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0935 - acc: 0.8516\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0907 - acc: 0.8513\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0864 - acc: 0.8507\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0804 - acc: 0.8499\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0736 - acc: 0.8487\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0689 - acc: 0.8474\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0683 - acc: 0.8473\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0678 - acc: 0.8471\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0672 - acc: 0.8471\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0665 - acc: 0.8470\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #36\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0783 - acc: 0.7724\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0810 - acc: 0.7726\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0807 - acc: 0.7746\n",
      "Epoch 4/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0781 - acc: 0.7767\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0739 - acc: 0.7746\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0686 - acc: 0.7572\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0649 - acc: 0.7133\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0645 - acc: 0.7044\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0641 - acc: 0.6952\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0638 - acc: 0.6858\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0634 - acc: 0.6764\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #37\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0390 - acc: 0.8402\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0382 - acc: 0.8311\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0359 - acc: 0.8548\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0325 - acc: 0.8933\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0289 - acc: 0.9286\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0255 - acc: 0.9483\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0232 - acc: 0.9581\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0230 - acc: 0.9589\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0228 - acc: 0.9593\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0226 - acc: 0.9596\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0224 - acc: 0.9597\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #38\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0780 - acc: 0.7604\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0761 - acc: 0.7609\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0732 - acc: 0.7611\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0707 - acc: 0.7611\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0678 - acc: 0.7611\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0649 - acc: 0.7609\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0631 - acc: 0.7607\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0628 - acc: 0.7607\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0626 - acc: 0.7606\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0623 - acc: 0.7606\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0620 - acc: 0.7605\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #39\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0443 - acc: 0.5835\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0414 - acc: 0.5868\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0381 - acc: 0.5928\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0358 - acc: 0.5977\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0346 - acc: 0.5993\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0340 - acc: 0.5981\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0336 - acc: 0.5955\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0335 - acc: 0.5951\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0334 - acc: 0.5947\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0333 - acc: 0.5944\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0331 - acc: 0.5942\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #40\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0915 - acc: 0.6960\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0818 - acc: 0.6925\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0773 - acc: 0.6889\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0765 - acc: 0.6886\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0709 - acc: 0.6919\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0676 - acc: 0.6928\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0697 - acc: 0.6910\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0692 - acc: 0.6915\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0682 - acc: 0.6925\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0669 - acc: 0.6938\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0657 - acc: 0.6954\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #41\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0451 - acc: 0.4354\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0455 - acc: 0.4252\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0454 - acc: 0.4240\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0447 - acc: 0.4257\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0443 - acc: 0.4330\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0444 - acc: 0.4492\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0446 - acc: 0.4679\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0446 - acc: 0.4704\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0445 - acc: 0.4727\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0444 - acc: 0.4747\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0443 - acc: 0.4764\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #42\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0623 - acc: 0.7817\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0625 - acc: 0.7522\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0617 - acc: 0.7225\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0606 - acc: 0.7030\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0598 - acc: 0.7036\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0593 - acc: 0.7281\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0588 - acc: 0.7584\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0587 - acc: 0.7636\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0586 - acc: 0.7699\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0584 - acc: 0.7767\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0583 - acc: 0.7835\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #43\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0984 - acc: 0.6472\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0956 - acc: 0.6584\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0938 - acc: 0.6625\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0907 - acc: 0.6625\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0868 - acc: 0.6604\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0843 - acc: 0.6575\n",
      "Epoch 7/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0828 - acc: 0.6555\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0825 - acc: 0.6554\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0822 - acc: 0.6553\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0818 - acc: 0.6554\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0815 - acc: 0.6554\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #44\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.1532 - acc: 0.7150\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.1116 - acc: 0.7134\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0639 - acc: 0.6968\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0581 - acc: 0.6238\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0757 - acc: 0.5707\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0819 - acc: 0.5886\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0792 - acc: 0.6348\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0780 - acc: 0.6409\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0762 - acc: 0.6473\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0740 - acc: 0.6533\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0715 - acc: 0.6588\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #45\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0564 - acc: 0.5224\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0482 - acc: 0.5463\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0430 - acc: 0.5443\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0441 - acc: 0.5333\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0446 - acc: 0.5240\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0427 - acc: 0.5133\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0419 - acc: 0.4941\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0419 - acc: 0.4911\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0419 - acc: 0.4888\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0419 - acc: 0.4874\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0418 - acc: 0.4865\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #46\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0517 - acc: 0.6385\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0497 - acc: 0.6451\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0468 - acc: 0.6507\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0442 - acc: 0.6555\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0431 - acc: 0.6589\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0430 - acc: 0.6608\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0430 - acc: 0.6618\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0429 - acc: 0.6618\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0428 - acc: 0.6617\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0427 - acc: 0.6616\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0426 - acc: 0.6615\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #47\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0367 - acc: 0.6778\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0339 - acc: 0.6935\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 269ms/step - loss: 0.0293 - acc: 0.7340\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0284 - acc: 0.7510\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0288 - acc: 0.7536\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0248 - acc: 0.7274\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0234 - acc: 0.6602\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0234 - acc: 0.6547\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0232 - acc: 0.6525\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 269ms/step - loss: 0.0230 - acc: 0.6528\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0228 - acc: 0.6552\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #48\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0775 - acc: 0.6994\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0653 - acc: 0.7114\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0546 - acc: 0.7281\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0569 - acc: 0.7435\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0609 - acc: 0.7534\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0581 - acc: 0.7596\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0529 - acc: 0.7626\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0522 - acc: 0.7629\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0515 - acc: 0.7631\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0508 - acc: 0.7632\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0503 - acc: 0.7633\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #49\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0478 - acc: 0.7382\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0445 - acc: 0.7597\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0454 - acc: 0.7790\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0480 - acc: 0.7874\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0481 - acc: 0.7834\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0459 - acc: 0.7697\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0444 - acc: 0.7564\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0443 - acc: 0.7551\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0442 - acc: 0.7543\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0441 - acc: 0.7540\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0440 - acc: 0.7542\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #50\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0550 - acc: 0.4713\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0457 - acc: 0.4355\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0433 - acc: 0.3739\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0437 - acc: 0.3405\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0436 - acc: 0.3526\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0427 - acc: 0.4044\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0418 - acc: 0.4519\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0417 - acc: 0.4572\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0416 - acc: 0.4621\n",
      "Epoch 10/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0415 - acc: 0.4666\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0414 - acc: 0.4708\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #51\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.1195 - acc: 0.7799\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0944 - acc: 0.8255\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0716 - acc: 0.8249\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0612 - acc: 0.8175\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0578 - acc: 0.8242\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0575 - acc: 0.8377\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0566 - acc: 0.8465\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0563 - acc: 0.8474\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0558 - acc: 0.8484\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0553 - acc: 0.8492\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0547 - acc: 0.8501\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #52\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0950 - acc: 0.9717\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0803 - acc: 0.9721\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0711 - acc: 0.9722\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0684 - acc: 0.9723\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0704 - acc: 0.9723\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0730 - acc: 0.9723\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0740 - acc: 0.9723\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0739 - acc: 0.9723\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0735 - acc: 0.9723\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0729 - acc: 0.9723\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0722 - acc: 0.9723\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #53\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0528 - acc: 0.7626\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0523 - acc: 0.7626\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0516 - acc: 0.7626\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0502 - acc: 0.7626\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0478 - acc: 0.7626\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0446 - acc: 0.7626\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0422 - acc: 0.7626\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0419 - acc: 0.7626\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0415 - acc: 0.7626\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0412 - acc: 0.7626\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0409 - acc: 0.7625\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #54\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0536 - acc: 0.6883\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0517 - acc: 0.6841\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0486 - acc: 0.6767\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0449 - acc: 0.6583\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0416 - acc: 0.6437\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0391 - acc: 0.6424\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0386 - acc: 0.6440\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0386 - acc: 0.6447\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0385 - acc: 0.6458\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0385 - acc: 0.6474\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0384 - acc: 0.6492\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #55\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0372 - acc: 0.8394\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0359 - acc: 0.8493\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0346 - acc: 0.8520\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0335 - acc: 0.8529\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0327 - acc: 0.8534\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0321 - acc: 0.8536\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0318 - acc: 0.8537\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0318 - acc: 0.8537\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0317 - acc: 0.8537\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0317 - acc: 0.8537\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0317 - acc: 0.8537\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #56\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0461 - acc: 0.8451\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0449 - acc: 0.8450\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0437 - acc: 0.8449\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0426 - acc: 0.8447\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0417 - acc: 0.8444\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0410 - acc: 0.8439\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0406 - acc: 0.8436\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0405 - acc: 0.8435\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0405 - acc: 0.8435\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0404 - acc: 0.8435\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0404 - acc: 0.8435\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #57\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0712 - acc: 0.8649\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0695 - acc: 0.8649\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0656 - acc: 0.8649\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0612 - acc: 0.8648\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0575 - acc: 0.8647\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0552 - acc: 0.8643\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0541 - acc: 0.8639\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0539 - acc: 0.8639\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0538 - acc: 0.8638\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0536 - acc: 0.8638\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0534 - acc: 0.8638\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #58\n",
      "Epoch 1/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 287ms/step - loss: 0.1046 - acc: 0.5772\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0986 - acc: 0.5768\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0901 - acc: 0.5757\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0838 - acc: 0.5736\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0815 - acc: 0.5690\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0809 - acc: 0.5603\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0795 - acc: 0.5496\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0789 - acc: 0.5483\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0781 - acc: 0.5472\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0771 - acc: 0.5462\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0759 - acc: 0.5454\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #59\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0636 - acc: 0.6823\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0633 - acc: 0.6953\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0647 - acc: 0.7225\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0661 - acc: 0.7488\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0664 - acc: 0.7666\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.0654 - acc: 0.7757\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0640 - acc: 0.7795\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0637 - acc: 0.7799\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0634 - acc: 0.7801\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0630 - acc: 0.7803\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0626 - acc: 0.7805\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #60\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0792 - acc: 0.8868\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0783 - acc: 0.8994\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0767 - acc: 0.9076\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0737 - acc: 0.9114\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0705 - acc: 0.9129\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0681 - acc: 0.9134\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0670 - acc: 0.9139\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0669 - acc: 0.9140\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0668 - acc: 0.9142\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0667 - acc: 0.9144\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0666 - acc: 0.9147\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #61\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.1041 - acc: 0.8837\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0989 - acc: 0.8836\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0933 - acc: 0.8835\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0896 - acc: 0.8829\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0868 - acc: 0.8822\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0837 - acc: 0.8816\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0809 - acc: 0.8812\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0805 - acc: 0.8812\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0800 - acc: 0.8812\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0794 - acc: 0.8813\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0789 - acc: 0.8814\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #62\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0666 - acc: 0.1377\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0653 - acc: 0.1377\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0558 - acc: 0.1378\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0437 - acc: 0.1378\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0378 - acc: 0.1378\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0368 - acc: 0.1378\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0368 - acc: 0.1379\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0368 - acc: 0.1379\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0366 - acc: 0.1379\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0365 - acc: 0.1380\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0363 - acc: 0.1379\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #63\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.1021 - acc: 0.7785\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.1017 - acc: 0.7136\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0999 - acc: 0.6464\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0971 - acc: 0.5914\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0934 - acc: 0.5532\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0890 - acc: 0.5316\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0851 - acc: 0.5251\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0845 - acc: 0.5257\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0838 - acc: 0.5275\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0831 - acc: 0.5302\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0824 - acc: 0.5335\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #64\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0506 - acc: 0.6551\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0475 - acc: 0.7207\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0489 - acc: 0.7979\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0504 - acc: 0.8455\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0476 - acc: 0.8666\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0429 - acc: 0.8780\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0411 - acc: 0.8836\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0411 - acc: 0.8842\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0411 - acc: 0.8847\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0411 - acc: 0.8851\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0410 - acc: 0.8855\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #65\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0808 - acc: 0.7404\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0765 - acc: 0.7388\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0725 - acc: 0.7343\n",
      "Epoch 4/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0708 - acc: 0.7170\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0700 - acc: 0.6811\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0693 - acc: 0.6601\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0688 - acc: 0.6606\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0687 - acc: 0.6631\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0686 - acc: 0.6674\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0684 - acc: 0.6729\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0681 - acc: 0.6788\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #66\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0383 - acc: 0.5251\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0379 - acc: 0.5293\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0376 - acc: 0.5314\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0372 - acc: 0.5323\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0369 - acc: 0.5329\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0365 - acc: 0.5332\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0363 - acc: 0.5334\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0363 - acc: 0.5334\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0362 - acc: 0.5334\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0362 - acc: 0.5334\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0362 - acc: 0.5334\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #67\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.1167 - acc: 0.9866\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.1130 - acc: 0.9890\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.1068 - acc: 0.9905\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.1003 - acc: 0.9909\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0946 - acc: 0.9913\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0892 - acc: 0.9921\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0855 - acc: 0.9926\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0851 - acc: 0.9926\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0846 - acc: 0.9926\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0840 - acc: 0.9926\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0834 - acc: 0.9926\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #68\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.1183 - acc: 0.8337\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.1093 - acc: 0.8333\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.1000 - acc: 0.8328\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0917 - acc: 0.8310\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0854 - acc: 0.8201\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0816 - acc: 0.7953\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0787 - acc: 0.7862\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 0.0782 - acc: 0.7862\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0776 - acc: 0.7881\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0771 - acc: 0.7889\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0766 - acc: 0.7879\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #69\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0834 - acc: 0.8899\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0816 - acc: 0.9158\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0804 - acc: 0.9236\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0800 - acc: 0.9242\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0791 - acc: 0.9243\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0775 - acc: 0.9242\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0757 - acc: 0.9239\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0753 - acc: 0.9238\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0749 - acc: 0.9238\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0744 - acc: 0.9237\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0739 - acc: 0.9236\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #70\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.1186 - acc: 0.4800\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.1117 - acc: 0.4741\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.1043 - acc: 0.4682\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0974 - acc: 0.4459\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0910 - acc: 0.3999\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0869 - acc: 0.3578\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0845 - acc: 0.3381\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0838 - acc: 0.3373\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0830 - acc: 0.3379\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0822 - acc: 0.3393\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0816 - acc: 0.3415\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #71\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0635 - acc: 0.5476\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0608 - acc: 0.6450\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0593 - acc: 0.6488\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0568 - acc: 0.6515\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0541 - acc: 0.6531\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0519 - acc: 0.6541\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0508 - acc: 0.6545\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0507 - acc: 0.6546\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0506 - acc: 0.6545\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0505 - acc: 0.6545\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0504 - acc: 0.6545\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #72\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.1071 - acc: 0.8810\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.1039 - acc: 0.8856\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.1004 - acc: 0.8914\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0971 - acc: 0.8949\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0939 - acc: 0.8969\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0900 - acc: 0.8983\n",
      "Epoch 7/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0863 - acc: 0.8994\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0857 - acc: 0.8997\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0849 - acc: 0.9003\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0841 - acc: 0.9009\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0833 - acc: 0.9016\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #73\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0371 - acc: 0.8139\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0379 - acc: 0.8149\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0406 - acc: 0.8152\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0421 - acc: 0.8154\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0410 - acc: 0.8151\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0383 - acc: 0.8131\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0362 - acc: 0.8083\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0359 - acc: 0.8076\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0357 - acc: 0.8071\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0354 - acc: 0.8069\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0352 - acc: 0.8069\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #74\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0774 - acc: 0.8067\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0782 - acc: 0.8062\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0750 - acc: 0.8056\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0730 - acc: 0.8047\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0715 - acc: 0.8031\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0713 - acc: 0.8007\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0706 - acc: 0.7988\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0698 - acc: 0.7987\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0697 - acc: 0.7987\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0700 - acc: 0.7988\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0697 - acc: 0.7991\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #75\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0425 - acc: 0.7750\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0375 - acc: 0.7868\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0351 - acc: 0.7881\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0359 - acc: 0.7881\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0325 - acc: 0.7881\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0297 - acc: 0.7878\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0297 - acc: 0.7868\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0297 - acc: 0.7866\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0294 - acc: 0.7865\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0291 - acc: 0.7864\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0288 - acc: 0.7864\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #76\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0494 - acc: 0.8921\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0434 - acc: 0.8999\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0459 - acc: 0.8999\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0468 - acc: 0.8993\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0426 - acc: 0.8976\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0383 - acc: 0.8930\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0382 - acc: 0.8879\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0382 - acc: 0.8887\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0381 - acc: 0.8908\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0378 - acc: 0.8935\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0375 - acc: 0.8964\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #77\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0617 - acc: 0.8517\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 277ms/step - loss: 0.0614 - acc: 0.8535\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0570 - acc: 0.8542\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0540 - acc: 0.8545\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0534 - acc: 0.8548\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0529 - acc: 0.8549\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0519 - acc: 0.8547\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0516 - acc: 0.8547\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0513 - acc: 0.8547\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0510 - acc: 0.8546\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0506 - acc: 0.8546\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #78\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0735 - acc: 0.9578\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0698 - acc: 0.9573\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0635 - acc: 0.9573\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0624 - acc: 0.9573\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0611 - acc: 0.9570\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0582 - acc: 0.9569\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0554 - acc: 0.9569\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0550 - acc: 0.9570\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0544 - acc: 0.9571\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0538 - acc: 0.9572\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0532 - acc: 0.9572\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #79\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0456 - acc: 0.8606\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0467 - acc: 0.8613\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0475 - acc: 0.8615\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0479 - acc: 0.8615\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0477 - acc: 0.8614\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0468 - acc: 0.8613\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0458 - acc: 0.8612\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0456 - acc: 0.8612\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0454 - acc: 0.8611\n",
      "Epoch 10/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0452 - acc: 0.8610\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0449 - acc: 0.8609\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Training batch #80\n",
      "Epoch 1/11\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.0318 - acc: 0.8735\n",
      "Epoch 2/11\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0294 - acc: 0.5614\n",
      "Epoch 3/11\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0273 - acc: 0.4848\n",
      "Epoch 4/11\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0256 - acc: 0.4642\n",
      "Epoch 5/11\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0241 - acc: 0.4432\n",
      "Epoch 6/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0232 - acc: 0.4274\n",
      "Epoch 7/11\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0229 - acc: 0.4225\n",
      "Epoch 8/11\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.0228 - acc: 0.4232\n",
      "Epoch 9/11\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0225 - acc: 0.4249\n",
      "Epoch 10/11\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0221 - acc: 0.4271\n",
      "Epoch 11/11\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0216 - acc: 0.4299\n",
      "Saved model -> model.h5\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# better training\n",
    "#\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import rawpy\n",
    "\n",
    "from keras import backend as k\n",
    "from keras.layers import \\\n",
    "Input, Conv2D, LeakyReLU, MaxPooling2D, \\\n",
    "UpSampling2D, Conv2DTranspose, Concatenate, \\\n",
    "ZeroPadding2D, UpSampling3D\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import keras.layers.advanced_activations\n",
    "import keras.optimizers\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Constants\n",
    "target_dir = './dataset/Sony/long/'\n",
    "input_dir = './dataset/Sony/short/'\n",
    "\n",
    "ps = 512 # patch size\n",
    "\n",
    "# Helper Functions\n",
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out\n",
    "  \n",
    "def load_batches(batch_size):   \n",
    "    train_fns = glob.glob(target_dir + '0*.ARW') \n",
    "    train_ids = np.array([int(os.path.basename(train_fn)[0:5]) \\\n",
    "                          for train_fn in train_fns])\n",
    "    \n",
    "    train_ids = np.random.permutation(train_ids)\n",
    "    \n",
    "    total_length = len(train_ids)\n",
    "    \n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < total_length:\n",
    "            limit = min(batch_end, total_length)  \n",
    "            batch_ids = train_ids[batch_start:limit]\n",
    "            \n",
    "            # Intialize return values\n",
    "            inputs, targets = np.empty((batch_size,ps,ps,4)), np.empty((batch_size,ps*2,ps*2,3))\n",
    "            index = 0\n",
    "            for image_id in batch_ids:\n",
    "              \n",
    "                # Get an random input filename\n",
    "                input_files = glob.glob(input_dir + '%05d_00*.ARW' % image_id)\n",
    "                input_path = None\n",
    "                if len(input_files) <= 1:\n",
    "                    input_path = input_files[0]\n",
    "                else :\n",
    "                    input_path = input_files[np.random.randint(0, len(input_files) - 1)]\n",
    "                input_fn = os.path.basename(input_path)\n",
    "\n",
    "                # Get the matching target name\n",
    "                target_files = glob.glob(target_dir + '%05d_00*.ARW' % image_id)\n",
    "                target_path = target_files[0]\n",
    "                target_fn = os.path.basename(target_path)\n",
    "                          \n",
    "                # Calculate amplification ratio\n",
    "                input_exposure = float(input_fn[9:-5])\n",
    "                target_exposure = float(target_fn[9:-5])\n",
    "                ratio = min(target_exposure / input_exposure, 300)\n",
    "                \n",
    "                # Load image into memory\n",
    "                raw = rawpy.imread(input_path)\n",
    "                input_image = \\\n",
    "                  np.expand_dims(pack_raw(raw), axis=0) * ratio\n",
    "\n",
    "                target_image = rawpy.imread(target_path)\n",
    "                target_image = target_image.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "                target_image = np.expand_dims(np.float32(target_image / 65535.0), axis=0)\n",
    "\n",
    "                # Take a random patch from each image\n",
    "                H = input_image.shape[1]\n",
    "                W = input_image.shape[2]\n",
    "\n",
    "                xx = np.random.randint(0, W - ps)\n",
    "                yy = np.random.randint(0, H - ps)\n",
    "                input_patch = input_image[:, yy:yy + ps, xx:xx + ps, :]\n",
    "                target_patch = target_image[:, yy * 2:yy * 2 + ps * 2, xx * 2:xx * 2 + ps * 2, :]\n",
    "        \n",
    "                # Compute random alterations to the images\n",
    "                if np.random.randint(2, size=1)[0] == 1:  # random flip\n",
    "                    input_patch = np.flip(input_patch, axis=1)\n",
    "                    target_patch = np.flip(target_patch, axis=1)\n",
    "                if np.random.randint(2, size=1)[0] == 1:\n",
    "                    input_patch = np.flip(input_patch, axis=2)\n",
    "                    target_patch = np.flip(target_patch, axis=2)\n",
    "                if np.random.randint(2, size=1)[0] == 1:  # random transpose\n",
    "                    input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
    "                    target_patch = np.transpose(target_patch, (0, 2, 1, 3))\n",
    "\n",
    "                input_patch = np.minimum(input_patch, 1.0)\n",
    "\n",
    "                # Add to return arrays\n",
    "                inputs[index] = input_patch\n",
    "                targets[index] = target_patch\n",
    "                \n",
    "                del input_patch\n",
    "                del target_patch\n",
    "                \n",
    "                index += 1\n",
    "\n",
    "            yield (inputs,targets,(batch_start/batch_size))\n",
    "\n",
    "            del inputs\n",
    "            del targets\n",
    "            \n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size\n",
    "            \n",
    "        return\n",
    "\n",
    "def main():\n",
    "    # Backend Config\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "    tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
    "    k.set_image_data_format('channels_last')\n",
    "    \n",
    "    # Define the model\n",
    "    inputs = Input(shape=(None,None,4,), dtype=\"float32\",\n",
    "                name=\"Inputs\")\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=(3,3),\n",
    "            name=\"conv_1_1\", padding='same')(inputs)\n",
    "    x = LeakyReLU(alpha=0.2, name=\"conv_1_act_1\")(x)\n",
    "    x = Conv2D(filters=32, kernel_size=(3,3),\n",
    "            name=\"conv_1_2\", padding='same')(x)\n",
    "    x1 = LeakyReLU(alpha=0.2, name=\"conv_1_act_2\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same',\n",
    "            name=\"conv_1_pool\")(x1)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3),\n",
    "            name=\"conv_2_1\", padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=\"conv_2_act_1\")(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3),\n",
    "            name=\"conv_2_2\", padding='same')(x)\n",
    "    x2 = LeakyReLU(alpha=0.2, name=\"conv_2_act_2\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same',\n",
    "            name=\"conv_2_pool\")(x2)\n",
    "\n",
    "    x = Conv2D(filters=128, kernel_size=(3,3),\n",
    "            name=\"conv_3_1\", padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=\"conv_3_act_1\")(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3,3),\n",
    "            name=\"conv_3_2\", padding='same')(x)\n",
    "    x3 = LeakyReLU(alpha=0.2, name=\"conv_3_act_2\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same',\n",
    "            name=\"conv_3_pool\")(x3)\n",
    "\n",
    "    x = Conv2D(filters=256, kernel_size=(3,3),\n",
    "            name=\"conv_4_1\", padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=\"conv_4_act_1\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3,3),\n",
    "            name=\"conv_4_2\", padding='same')(x)\n",
    "    x4 = LeakyReLU(alpha=0.2, name=\"conv_4_act_2\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same',\n",
    "            name=\"conv_4_pool\")(x4)\n",
    "\n",
    "    x = Conv2D(filters=512, kernel_size=(3,3),\n",
    "            name=\"conv_5_1\", padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=\"conv_5_act_1\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3,3),\n",
    "            name=\"conv_5_2\", padding='same')(x)\n",
    "    x5 = LeakyReLU(alpha=0.2, name=\"conv_5_act_2\")(x)\n",
    "    \n",
    "    x5 = Conv2DTranspose(filters=256, kernel_size=(2,2),\n",
    "            strides=(2,2), padding='same')(x5)\n",
    "    x = Concatenate(axis=3)([x5,x4])\n",
    "    x = Conv2D(filters=256, kernel_size=(3,3),\n",
    "            name=\"conv_7_1\", padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=\"conv_7_act_1\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3,3),\n",
    "            name=\"conv_7_2\", padding='same')(x)\n",
    "    x6 = LeakyReLU(alpha=0.2, name=\"conv_7_act_2\")(x)\n",
    "\n",
    "    x6 = Conv2DTranspose(filters=128, kernel_size=(2,2),\n",
    "            strides=(2,2), padding='same')(x6)\n",
    "    x = Concatenate(axis=3)([x6,x3])\n",
    "    x = Conv2D(filters=128, kernel_size=(3,3),\n",
    "            name=\"conv_8_1\", padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=\"conv_8_act_1\")(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3,3),\n",
    "            name=\"conv_8_2\", padding='same')(x)\n",
    "    x7 = LeakyReLU(alpha=0.2, name=\"conv_8_act_2\")(x)\n",
    "\n",
    "    x7 = Conv2DTranspose(filters=64, kernel_size=(2,2),\n",
    "            strides=(2,2), padding='same')(x7)\n",
    "    x = Concatenate(axis=3)([x7,x2])\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3),\n",
    "            name=\"conv_9_1\", padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=\"conv_9_act_1\")(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3),\n",
    "            name=\"conv_9_2\", padding='same')(x)\n",
    "    x8 = LeakyReLU(alpha=0.2, name=\"conv_9_act_2\")(x)\n",
    "\n",
    "    x8 = Conv2DTranspose(filters=32, kernel_size=(2,2),\n",
    "            strides=(2,2), padding='same')(x8)\n",
    "    x = Concatenate(axis=3)([x8,x1])\n",
    "    x = Conv2D(filters=32, kernel_size=(3,3),\n",
    "            name=\"conv_10_1\", padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=\"conv_10_act_1\")(x)\n",
    "    x = Conv2D(filters=32, kernel_size=(3,3),\n",
    "            name=\"conv_10_2\", padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=\"conv_10_act_2\")(x)\n",
    "\n",
    "    x = Conv2D(filters=3, kernel_size=(1,1), activation=None,\n",
    "            name=\"conv_to_image\")(x)\n",
    "\n",
    "    outputs = UpSampling2D(size=(2,2))(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='ltsitd')\n",
    "\n",
    "    # Get info about the model\n",
    "    if False:\n",
    "        model.summary(line_length=150)\n",
    "        \n",
    "        plot_model(model, to_file='model.png')\n",
    "        from google.colab import files\n",
    "        files.download('model.png')\n",
    "    \n",
    "    batch_size = 2          # Number of images to load into memory at once (RAM/GPU Memory restricted)\n",
    "    total_epochs = 11       # Number of training rounds per batch\n",
    "\n",
    "    # Drop the learning rate by a factor of 10 halfway through\n",
    "    def step_decay(epoch):\n",
    "        lrate = 1e-4\n",
    "        \n",
    "        if epoch > total_epochs // 2:\n",
    "          lrate = 1e-5\n",
    "        \n",
    "        return lrate\n",
    "      \n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "    callback_list = [lrate]\n",
    "    \n",
    "    # Build the model\n",
    "    model.compile(loss='mae',          # mean absolute error for loss\n",
    "                  optimizer='Adam',    # Adam optimizer\n",
    "                  metrics=['acc'])     # Print accuracy info during training\n",
    "\n",
    "    # Train the model\n",
    "    for inputs, targets, batch in load_batches(batch_size):\n",
    "        print('\\n------------------------------------------------------------------------------------')\n",
    "        print(\"Training batch #%d\" % batch)\n",
    "        model.fit(inputs, \n",
    "                  targets,\n",
    "                  steps_per_epoch=batch_size,\n",
    "                  epochs=total_epochs,\n",
    "                  callbacks=callback_list, # Call the step_decay function\n",
    "                  verbose=1)\n",
    "    \n",
    "    # Save model\n",
    "    model.save('model.h5') \n",
    "    print('Saved model -> model.h5')\n",
    "    del model \n",
    "\n",
    "# Run the program\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_CLsAAK8QS1"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USsnFwAI22bz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved test_00182.jpg\n",
      "saved test_20211.jpg\n",
      "saved test_00186.jpg\n",
      "saved test_00222.jpg\n",
      "saved test_00209.jpg\n",
      "saved test_00232.jpg\n",
      "saved test_20201.jpg\n",
      "saved test_10054.jpg\n",
      "saved test_00207.jpg\n",
      "saved test_00215.jpg\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import imageio\n",
    "import rawpy\n",
    "import numpy as np\n",
    "\n",
    "DIR = 'dataset/Sony/short/'\n",
    "\n",
    "INPUTS=[\n",
    "    '00182_03_0.04s.ARW',\n",
    "    '20211_01_0.033s.ARW',\n",
    "    '00186_01_0.033s.ARW',\n",
    "    '00222_05_0.04s.ARW',\n",
    "    '00209_00_0.033s.ARW',\n",
    "    '00232_03_0.04s.ARW', \n",
    "    '20201_03_0.04s.ARW',\n",
    "    '10054_01_0.04s.ARW',\n",
    "    '00207_01_0.04s.ARW',\n",
    "    '00215_00_0.033s.ARW'\n",
    "]\n",
    "\n",
    "OUT_FMT='test_%s.jpg'\n",
    "\n",
    "# Loads the saved model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "for image in INPUTS:\n",
    "    iid = image[0:5]\n",
    "    raw = rawpy.imread(DIR+image)\n",
    "\n",
    "    i = np.expand_dims(pack_raw(raw), axis=0) * 200\n",
    "    i = np.minimum(i, 1.0)\n",
    "\n",
    "    # Runs the model on a new input image\n",
    "    output = model.predict(i)\n",
    "\n",
    "    output = np.minimum(np.maximum(output, 0), 1)\n",
    "    output = output[0, :, :, :]\n",
    "\n",
    "    output *= 255\n",
    "\n",
    "    imageio.imwrite(OUT_FMT % (iid), np.array(output, dtype=np.uint8))\n",
    "    print('saved %s' % (OUT_FMT % (iid)))\n",
    "\n",
    "#     files.download(DIR+image)\n",
    "#     files.download(OUT_FMT % (iid))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras_Sony.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
